{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "# P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "# Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "\n",
    "# Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n",
    "data = pd.read_csv(\"../data/airbnb-cleaned-mlflow.csv\").iloc[3:]\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"price\"], axis=1)\n",
    "test_x = test.drop([\"price\"], axis=1)\n",
    "train_y = train[[\"price\"]]\n",
    "test_y = test[[\"price\"]]\n",
    "\n",
    "alpha = 1.0\n",
    "l1_ratio = 0.1\n",
    "\n",
    "lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.1,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=42, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=1.000000, l1_ratio=0.100000):\n",
      "  RMSE: 102.36429084520508\n",
      "  MAE: 68.79511576580136\n",
      "  R2: 0.4956017439244397\n"
     ]
    }
   ],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "(rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation via local GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.1,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=42, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': (1.0, 0.5, 0.1), 'l1_ratio': [0.1, 0.5, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'alpha':(1.0, 0.5, 0.1), 'l1_ratio':[0.1, 0.5, 1.0]}\n",
    "cv = GridSearchCV(lr, parameters, cv=5, return_train_score=True)\n",
    "cv.fit(train_x, train_y)                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log result of grid search to Tracking Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00445299, 0.00343242, 0.00388966, 0.00367379, 0.00364747,\n",
       "        0.00423698, 0.00463667, 0.00440001, 0.00475092]),\n",
       " 'mean_score_time': array([0.00066805, 0.0006494 , 0.00058093, 0.00053859, 0.00060663,\n",
       "        0.00057282, 0.00054111, 0.00051818, 0.00053177]),\n",
       " 'mean_test_score': array([0.47245022, 0.48718442, 0.51964441, 0.49067956, 0.502159  ,\n",
       "        0.52088621, 0.51578271, 0.51869115, 0.54689143]),\n",
       " 'mean_train_score': array([0.48432243, 0.49928995, 0.53221285, 0.50351894, 0.51520673,\n",
       "        0.53462077, 0.52949625, 0.5327004 , 0.56317087]),\n",
       " 'param_alpha': masked_array(data=[1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_l1_ratio': masked_array(data=[0.1, 0.5, 1.0, 0.1, 0.5, 1.0, 0.1, 0.5, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 1.0, 'l1_ratio': 0.1},\n",
       "  {'alpha': 1.0, 'l1_ratio': 0.5},\n",
       "  {'alpha': 1.0, 'l1_ratio': 1.0},\n",
       "  {'alpha': 0.5, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.5, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.5, 'l1_ratio': 1.0},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.1, 'l1_ratio': 1.0}],\n",
       " 'rank_test_score': array([9, 8, 3, 7, 6, 2, 5, 4, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.47107917, 0.49097476, 0.53484277, 0.49545408, 0.51023135,\n",
       "        0.53652602, 0.52847455, 0.53309067, 0.56727678]),\n",
       " 'split0_train_score': array([0.48272443, 0.4975155 , 0.52900586, 0.50145841, 0.51277536,\n",
       "        0.53081083, 0.5266037 , 0.52970433, 0.55901005]),\n",
       " 'split1_test_score': array([0.50157094, 0.51876541, 0.5577848 , 0.52359254, 0.53712366,\n",
       "        0.55933187, 0.55328784, 0.55714815, 0.59149973]),\n",
       " 'split1_train_score': array([0.47804589, 0.49242423, 0.52445176, 0.49679803, 0.50811536,\n",
       "        0.52600805, 0.52188918, 0.52496623, 0.55466589]),\n",
       " 'split2_test_score': array([0.46161426, 0.47512211, 0.50947238, 0.47665076, 0.48850266,\n",
       "        0.51173341, 0.50460702, 0.50825901, 0.52698813]),\n",
       " 'split2_train_score': array([0.48705035, 0.50206849, 0.53391968, 0.50560853, 0.51702317,\n",
       "        0.53748583, 0.53114885, 0.53433088, 0.5664312 ]),\n",
       " 'split3_test_score': array([0.43255652, 0.4406315 , 0.45766131, 0.44313203, 0.44956647,\n",
       "        0.45754475, 0.45530459, 0.45560201, 0.48327786]),\n",
       " 'split3_train_score': array([0.49708839, 0.51219779, 0.54570031, 0.51679995, 0.52870834,\n",
       "        0.54921884, 0.54316165, 0.54636959, 0.57647436]),\n",
       " 'split4_test_score': array([0.49540624, 0.51039525, 0.53839958, 0.51453484, 0.52532918,\n",
       "        0.53923126, 0.53718421, 0.53929574, 0.56535068]),\n",
       " 'split4_train_score': array([0.47670307, 0.49224374, 0.52798662, 0.49692977, 0.50941141,\n",
       "        0.5295803 , 0.52467788, 0.52813098, 0.55927287]),\n",
       " 'std_fit_time': array([0.00048682, 0.00024467, 0.00019887, 0.00042546, 0.00020483,\n",
       "        0.0005086 , 0.0005482 , 0.0002781 , 0.00027526]),\n",
       " 'std_score_time': array([9.26018498e-05, 1.55027482e-04, 1.36558703e-05, 3.82995534e-05,\n",
       "        5.31134525e-05, 5.23285277e-05, 7.80241110e-05, 5.04861348e-05,\n",
       "        4.75936516e-05]),\n",
       " 'std_test_score': array([0.02483766, 0.02779027, 0.03458398, 0.02874384, 0.03090322,\n",
       "        0.03507835, 0.03407551, 0.03520562, 0.03791277]),\n",
       " 'std_train_score': array([0.00735411, 0.00740633, 0.00739196, 0.00739709, 0.00742129,\n",
       "        0.0081904 , 0.00746894, 0.00747233, 0.00764793])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "\n",
    "def track(clf, name):\n",
    "    params = list(clf.param_grid.keys())\n",
    "    cv_results = clf.cv_results_\n",
    "    rank = cv_results[\"rank_test_score\"]\n",
    "\n",
    "    for i in range(len(rank)):\n",
    "        if i == clf.best_index_:\n",
    "            run_name = \"run %d (best run):\" % i\n",
    "        else:\n",
    "            run_name = \"run %d:\" % i\n",
    "        print(run_name)\n",
    "        with mlflow.start_run(run_name=run_name, nested=True) as run:\n",
    "            mlflow.log_param(\"folds\", clf.cv)\n",
    "            for param in params:\n",
    "                print(\"  -\", param, cv_results[\"param_%s\" % param][i])\n",
    "                mlflow.log_param(param, cv_results[\"param_%s\" % param][i])\n",
    "    \n",
    "            mlflow.log_metric(\"rank_test_score\" , cv_results[\"rank_test_score\"][i])\n",
    "            mlflow.log_metric(\"mean_train_score\", cv_results[\"mean_train_score\"][i])\n",
    "            mlflow.log_metric(\"std_train_score\",  cv_results[\"std_train_score\"][i])\n",
    "            mlflow.log_metric(\"mean_test_score\",  cv_results[\"mean_test_score\"][i])\n",
    "            mlflow.log_metric(\"std_test_score\",   cv_results[\"std_test_score\"][i])\n",
    "            if i == clf.best_index_:\n",
    "                mlflow.sklearn.log_model(cv.best_estimator_, \"model\")\n",
    "                local_path = os.path.join(\".\", \"%s\" % name)\n",
    "                local_csv = os.path.join(local_path, \"cv_results.csv\")\n",
    "                if not os.path.exists(local_path):\n",
    "                    os.mkdir(local_path)\n",
    "                pd.DataFrame(cv_results).sort_values(by='rank_test_score').to_csv(local_csv, index=False)\n",
    "                mlflow.log_artifact(local_csv, \"cv_results\")\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local tracking server**\n",
    "\n",
    "```bash\n",
    "cd /opt/mlflow-tracking-server/\n",
    "mkdir -p backend\n",
    "mkdir -p artifacts\n",
    "mlflow server --backend-store-uri ./backend --default-artifact-root ./artifacts/  --host 0.0.0.0\n",
    "```\n",
    "\n",
    "**In the project folder**\n",
    "\n",
    "```bash\n",
    "ln -s /opt/mlflow-tracking-server/artifacts artifacts\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0:\n",
      "  - alpha 1.0\n",
      "  - l1_ratio 0.1\n",
      "run 1:\n",
      "  - alpha 1.0\n",
      "  - l1_ratio 0.5\n",
      "run 2:\n",
      "  - alpha 1.0\n",
      "  - l1_ratio 1.0\n",
      "run 3:\n",
      "  - alpha 0.5\n",
      "  - l1_ratio 0.1\n",
      "run 4:\n",
      "  - alpha 0.5\n",
      "  - l1_ratio 0.5\n",
      "run 5:\n",
      "  - alpha 0.5\n",
      "  - l1_ratio 1.0\n",
      "run 6:\n",
      "  - alpha 0.1\n",
      "  - l1_ratio 0.1\n",
      "run 7:\n",
      "  - alpha 0.1\n",
      "  - l1_ratio 0.5\n",
      "run 8 (best run):\n",
      "  - alpha 0.1\n",
      "  - l1_ratio 1.0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5000\")\n",
    "\n",
    "experiment=\"airbnb-jupyter\"\n",
    "mlflow.set_experiment(experiment)\n",
    "\n",
    "track(cv, \"airbnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.set_tracking_uri(\"databricks://westeu\")\n",
    "\n",
    "#experiment=\"/Shared/experiments/airbnb-jupyter\"\n",
    "#mlflow.set_experiment(experiment)\n",
    "\n",
    "#track(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
