{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/pydbr/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Use a Databricks Connect enable environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Setup databricks connect\n",
    "\n",
    "- Cluster Spark configuration (Azure port 8787)\n",
    "\n",
    "    ```\n",
    "    spark.databricks.mlflow.trackMLlib.enabled true\n",
    "    spark.databricks.service.server.enabled true\n",
    "    spark.databricks.service.port 8787\n",
    "    ```\n",
    "    \n",
    "    \n",
    "- Laptop:\n",
    "\n",
    "    ```bash\n",
    "    pip install databricks-connect\n",
    "\n",
    "    cat ~/.databricks-connect\n",
    "    {\n",
    "      \"port\": \"8787\",\n",
    "      \"org_id\": \"......\",\n",
    "      \"token\": \"dapi......\",\n",
    "      \"host\": \"https://......azuredatabricks.net\",\n",
    "      \"cluster_id\": \".....\"\n",
    "    }\n",
    "    ```\n",
    "    \n",
    "2) **Ensure** that `scikit-learn` on remote cluster is the same as got installed when installing `spark-sklearn`\n",
    "\n",
    "3) Check connectivity: Call remote and get the hostname of the workers. They should start with the cluster name as given by `~/.databricks-connect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import spark_sklearn\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(spark.version)\n",
    "spark.sparkContext.range(4).map(lambda x: socket.gethostname()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Setup a local Tracking Server\n",
    "\n",
    "- Local tracking server\n",
    "\n",
    "    ```bash\n",
    "    cd /opt/mlflow-tracking-server/\n",
    "    mkdir -p backend\n",
    "    mkdir -p artifacts\n",
    "    mlflow server --backend-store-uri ./backend --default-artifact-root ./artifacts/  --host 0.0.0.0\n",
    "    ```\n",
    "\n",
    "\n",
    "- In the project folder (ensure that the local path to artifacts is the same as for the local tracking server)\n",
    "    \n",
    "    ```\n",
    "    ln -s /opt/mlflow-tracking-server/artifacts artifacts\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Define a cross validation function to switch between local and remote cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "class GridSearchCV():\n",
    "\n",
    "    def __init__(self, estimator, param_grid, *args, remote=False, **kwargs):\n",
    "        self.estimator = estimator\n",
    "        self.grid_size = reduce(lambda a,b: a*b, [len(p) for p in param_grid.values()])\n",
    "        self.remote = remote\n",
    "        self.results = None\n",
    "        \n",
    "        if remote:\n",
    "            self.gs = spark_sklearn.GridSearchCV(spark.sparkContext, estimator, param_grid, *args, **kwargs)\n",
    "        else:\n",
    "            self.gs = sklearn.model_selection.GridSearchCV(estimator, param_grid, *args, **kwargs)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        if self.remote:\n",
    "            print(\"Remote crossvalidation,\", end=\" \")\n",
    "        else:\n",
    "            print(\"Local crossvalidation,\", end=\" \")\n",
    "        print(\"paramter grid size: %d\\n\" % self.grid_size)\n",
    "        \n",
    "        self.results = self.gs.fit(x, y)\n",
    "        return self.results\n",
    "    \n",
    "    def log_cv(self, tracking_uri, experiment, name):\n",
    "        cv_results = self.results.cv_results_\n",
    "        best = self.results.best_index_\n",
    "        \n",
    "        timestamp = datetime.datetime.now().isoformat().split(\".\")[0].replace(\":\", \".\")\n",
    "\n",
    "        num_runs = len(cv_results[\"rank_test_score\"])\n",
    "        run_name = \"run %d (best run of %d):\" % (self.results.best_index_, num_runs)\n",
    "\n",
    "        mlflow.set_tracking_uri(tracking_uri)\n",
    "        mlflow.set_experiment(experiment)\n",
    "\n",
    "        with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    "            mlflow.log_param(\"folds\", self.results.cv)\n",
    "\n",
    "            print(\"Logging parameters\")\n",
    "            params = list(self.results.param_grid.keys())\n",
    "            for param in params:\n",
    "                mlflow.log_param(param, cv_results[\"param_%s\" % param][best])\n",
    "\n",
    "            print(\"Logging metrics\")\n",
    "            # mlflow.log_metric(\"rank_test_score\" , cv_results[\"rank_test_score\"][best])\n",
    "            # mlflow.log_metric(\"mean_train_score\", cv_results[\"mean_train_score\"][best])\n",
    "            # mlflow.log_metric(\"std_train_score\",  cv_results[\"std_train_score\"][best])\n",
    "            mlflow.log_metric(\"mean_test_score\",  cv_results[\"mean_test_score\"][best])\n",
    "            mlflow.log_metric(\"std_test_score\",   cv_results[\"std_test_score\"][best])\n",
    "\n",
    "            print(\"Logging model\")\n",
    "            mlflow.sklearn.log_model(self.results.best_estimator_, \"model\")\n",
    "\n",
    "            print(\"Logging CV results matrix\")\n",
    "            tempdir = tempfile.TemporaryDirectory().name\n",
    "            os.mkdir(tempdir)\n",
    "            filename = \"%s-%s-cv_results.csv\" % (name, timestamp)\n",
    "            csv = os.path.join(tempdir, filename)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                pd.DataFrame(cv_results).sort_values(by='rank_test_score').to_csv(csv, index=False)\n",
    "                \n",
    "            mlflow.log_artifact(csv, \"cv_results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Local model development\n",
    "\n",
    "### Local cross validation\n",
    "\n",
    "Use a small subset of the paramter space for development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local crossvalidation, paramter grid size: 32\n",
      "\n",
      "CPU times: user 3.24 s, sys: 67 ms, total: 3.3 s\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": [1, 3],\n",
    "    \"min_samples_split\": [2, 10],\n",
    "    \"min_samples_leaf\": [1, 10],\n",
    "    \"n_estimators\": [10, 20]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(RandomForestClassifier(), param_grid, remote=False)\n",
    "cv.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local tracking\n",
    "\n",
    "Only relevant for the model development, e.g. feature selection and transformation. No need to share with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging CV results matrix\n"
     ]
    }
   ],
   "source": [
    "cv.log_cv(\n",
    "    tracking_uri=\"http://localhost:5000\", \n",
    "    experiment=\"digits-spark-sklearn\", \n",
    "    name=\"digits-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Final cross validation\n",
    "\n",
    "### Remote cross validation \n",
    "\n",
    "Increase the parameter grid to the maximum that is of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote crossvalidation, paramter grid size: 864\n",
      "\n",
      "CPU times: user 351 ms, sys: 21.4 ms, total: 373 ms\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": [1, 3, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 3, 10],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": [10, 20, 40, 80]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(RandomForestClassifier(), param_grid, remote=True)\n",
    "cv.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging CV results matrix\n"
     ]
    }
   ],
   "source": [
    "cv.log_cv(\n",
    "    tracking_uri=\"databricks://westeu\", \n",
    "    experiment=\"/Shared/experiments/digits-spark-sklearn\", \n",
    "    name=\"digits-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
